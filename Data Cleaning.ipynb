{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d50f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "# Assign directory\n",
    "PATH = 'Top 100 Influencers' \n",
    "EXT = \"*.csv\"\n",
    "\n",
    "\n",
    "all_csv_files = [\n",
    "    file  # Just use the 'file' directly\n",
    "    for path, subdir, files in os.walk(PATH)\n",
    "    for file in glob(os.path.join(path, EXT))\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee282fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOOK INTO MERGING COLUMNS without the header\n",
    "\n",
    "# Read the first CSV file with headers\n",
    "first_file = all_csv_files[0]\n",
    "df = pd.read_csv(first_file, delimiter=',',  na_values=['N/A', '?', 'None'])  # Explicitly set the delimiter\n",
    "headers = df.columns.tolist()  # Store the headers\n",
    "# print(headers)\n",
    "# df.head()\n",
    "\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "df_merged= []\n",
    "# Create a list to store channel names\n",
    "channel_names = []\n",
    "\n",
    "# Define the extract_channel function\n",
    "def extract_channel(filename):\n",
    "    try:\n",
    "        return filename.split('_')[0]  # Extract the channel name from the filename\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting channel from filename: {filename} - Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b644ca91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through all CSV files (including the first one)\n",
    "for csv_file in all_csv_files:  # Process the first 10 [:10] files\n",
    "    df = pd.read_csv(csv_file, header=None, delimiter=',', names=headers)\n",
    "    channel_name = extract_channel(os.path.basename(csv_file))  # Extract channel name\n",
    "    \n",
    "    # Repeat the channel name for each row in the DataFrame (excluding the header)\n",
    "    channel_names.extend([channel_name] * (len(df) - 1))\n",
    "    \n",
    "    df_merged.append(df.iloc[1:, :])  # Remove header and append\n",
    "\n",
    "\n",
    "#without converting df_merged type list to dataframe\n",
    "final_df = pd.concat(df_merged, ignore_index=True)\n",
    "\n",
    "# Assign the channel names to the 'CHANNEL' column\n",
    "final_df['CHANNEL'] = channel_names  # Assign the list of channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6107c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print unique values in 'CHANNEL' column and the final DataFrame\n",
    "# print(\"Unique values in 'CHANNEL' column:\", final_df['CHANNEL'].unique())\n",
    "\n",
    "\n",
    "# Search for rows that contain 'kendalljenner' in any column (case-insensitive)\n",
    "\n",
    "# Iterate through each CSV file\n",
    "# for file in all_csv_files:\n",
    "#     try:\n",
    "#         # Load the dataset\n",
    "#         df = pd.read_csv(file, header=None, delimiter=',', names=headers)\n",
    "\n",
    "#         # Search for rows that contain 'kendalljenner' in any column (case-insensitive)\n",
    "#         search_result = df[df.apply(lambda row: row.astype(str).str.contains('@brunamarquezine', case=False, na=False).any(), axis=1)]\n",
    "# #         search_result = df[df.apply(lambda row: row.astype(str).str.fullmatch('zara', case=False, na=False).any(), axis=1)]\n",
    "#         # Print the filename and search result\n",
    "#         if not search_result.empty:\n",
    "#             print(f\"--- Results in file: {file} ---\")\n",
    "#             print(search_result)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading file {file}: {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d5f1e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.iloc[90:121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87280747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22638 entries, 0 to 22637\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   #                   22638 non-null  object\n",
      " 1   NAME                22638 non-null  object\n",
      " 2   FOLLOWERS           22552 non-null  object\n",
      " 3   ER                  21962 non-null  object\n",
      " 4   COUNTRY             22336 non-null  object\n",
      " 5   TOPIC OF INFLUENCE  12356 non-null  object\n",
      " 6   POTENTIAL REACH     22638 non-null  object\n",
      " 7   CHANNEL             22638 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d066ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#                         0\n",
      "NAME                      0\n",
      "FOLLOWERS                86\n",
      "ER                      676\n",
      "COUNTRY                 302\n",
      "TOPIC OF INFLUENCE    10282\n",
      "POTENTIAL REACH           0\n",
      "CHANNEL                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#number of missing entries in each column\n",
    "\n",
    "miss_values = final_df.isna().sum()\n",
    "print(miss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1698461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaN values in 'FOLLOWERS' and COUNTRY\n",
    "final_df.dropna(subset=['FOLLOWERS'], inplace=True)\n",
    "# final_df.dropna(subset=['COUNTRY'], inplace=True)\n",
    "# final_df.dropna(subset=['ER'], inplace=True)\n",
    "final_df.dropna(subset=['TOPIC OF INFLUENCE'], inplace=True)\n",
    "final_df = final_df.drop('#', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14beb32d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    0\n",
      "FOLLOWERS               0\n",
      "ER                     32\n",
      "COUNTRY               194\n",
      "TOPIC OF INFLUENCE      0\n",
      "POTENTIAL REACH         0\n",
      "CHANNEL                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "miss_values2 = final_df.isna().sum()\n",
    "print(miss_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b782560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyphen_count = (final_df['ER'] == '-').sum()\n",
    "# print(f\"Number of hyphens in 'ER' column: {hyphen_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4015fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12295 entries, 32 to 22637\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   NAME                12295 non-null  object\n",
      " 1   FOLLOWERS           12295 non-null  object\n",
      " 2   ER                  12263 non-null  object\n",
      " 3   COUNTRY             12101 non-null  object\n",
      " 4   TOPIC OF INFLUENCE  12295 non-null  object\n",
      " 5   POTENTIAL REACH     12295 non-null  object\n",
      " 6   CHANNEL             12295 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 768.4+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca53451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove '%' and convert to numeric\n",
    "# final_df['ER'] = final_df['ER'].str.replace('%', '', regex=False)  # Remove '%'\n",
    "final_df['ER'] = pd.to_numeric(final_df['ER'].str.replace('%', '', regex=False), errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a89df6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAME                     0\n",
       "FOLLOWERS                0\n",
       "ER                    2322\n",
       "COUNTRY                194\n",
       "TOPIC OF INFLUENCE       0\n",
       "POTENTIAL REACH          0\n",
       "CHANNEL                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac69afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert K,M,B to decimals \n",
    "\n",
    "from decimal import Decimal,InvalidOperation  # Import the Decimal class\n",
    "\n",
    "\n",
    "def convert_followers(followers_str):\n",
    "    \"\"\"Converts a string with K, M, or B suffixes to a Decimal value.\"\"\"\n",
    "    try:\n",
    "        followers_str = followers_str.upper()  # Standardize case\n",
    "        if followers_str[-1] in ('K', 'M', 'B'):\n",
    "            num, magnitude = followers_str[:-1], followers_str[-1]\n",
    "            magnitude_multiplier = {'K': 10**3, 'M': 10**6, 'B': 10**9}\n",
    "            return Decimal(num) * magnitude_multiplier[magnitude]\n",
    "        else:\n",
    "            return Decimal(followers_str)\n",
    "    except (InvalidOperation, TypeError, IndexError) as e:\n",
    "#         print(f\"Error converting value: {text} - Error: {e}\")  # Print the error message\n",
    "        return None\n",
    "\n",
    "    \n",
    "# Apply function to have K,M,B decimals \n",
    "\n",
    "final_df['FOLLOWERS'] = final_df['FOLLOWERS'].apply(convert_followers)\n",
    "final_df['POTENTIAL REACH'] = final_df['POTENTIAL REACH'].apply(convert_followers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bedf214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to FLOAT type FOLLOWERS and POTENTIAL REACH columns\n",
    "\n",
    "final_df['FOLLOWERS'] = pd.to_numeric(final_df['FOLLOWERS'], errors='coerce')\n",
    "final_df['POTENTIAL REACH'] = pd.to_numeric(final_df['POTENTIAL REACH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fcf5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(subset=['ER'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059a40bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9973 entries, 59 to 22635\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   NAME                9973 non-null   object \n",
      " 1   FOLLOWERS           9973 non-null   float64\n",
      " 2   ER                  9973 non-null   float64\n",
      " 3   COUNTRY             9837 non-null   object \n",
      " 4   TOPIC OF INFLUENCE  9973 non-null   object \n",
      " 5   POTENTIAL REACH     9973 non-null   float64\n",
      " 6   CHANNEL             9973 non-null   object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 623.3+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61227701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  final_df.iloc[90:121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd4e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'TOPIC OF INFLUENCE' column after standardization:\n",
      "['celebrity' 'cricket sports' 'art' ...\n",
      " 'nature outdoor activity fitness health education' 'finance politics'\n",
      " 'entertainment music family romance wedding education']\n"
     ]
    }
   ],
   "source": [
    "# Standardize the text in the 'Topic of Influence' column\n",
    "def standardize_topic(topic):\n",
    "    \"\"\"Standardizes the text in the 'Topic of Influence' column.\"\"\"\n",
    "    topic = topic.lower()\n",
    "    topic = ''.join(ch for ch in topic if ch.isalnum() or ch.isspace())\n",
    "    topic = ' '.join(topic.split())\n",
    "    return topic\n",
    "\n",
    "final_df['TOPIC OF INFLUENCE'] = final_df['TOPIC OF INFLUENCE'].astype(str).apply(standardize_topic)\n",
    "\n",
    "# Print the unique values in the 'TOPIC OF INFLUENCE' column\n",
    "print(\"Unique values in 'TOPIC OF INFLUENCE' column after standardization:\")\n",
    "print(final_df['TOPIC OF INFLUENCE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "918733f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n"
     ]
    }
   ],
   "source": [
    "duplicate_values = final_df['NAME'].duplicated().sum()\n",
    "print(duplicate_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420f5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on Name column\n",
    "final_df = final_df.drop_duplicates(subset=['NAME'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88ab0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "final_df.to_csv('merged_influencer_data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a288d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>FOLLOWERS</th>\n",
       "      <th>ER</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>TOPIC OF INFLUENCE</th>\n",
       "      <th>POTENTIAL REACH</th>\n",
       "      <th>CHANNEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pashto Entertainment Entertainment</td>\n",
       "      <td>UC5o5At6pto0EYYa0-m3GIiA</td>\n",
       "      <td>19400.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>celebrity</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>rashid.khan19</td>\n",
       "      <td>9100000.0</td>\n",
       "      <td>6.19</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>cricket sports</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Steve McCurry</td>\n",
       "      <td>stevemccurryofficial</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>art</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>د. وسيم يوسف</td>\n",
       "      <td>waseem_yousef</td>\n",
       "      <td>3300000.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>celebrities</td>\n",
       "      <td>993100.0</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHMAD SAEEDI / احمد سعيدي</td>\n",
       "      <td>ahmadsaeedi1</td>\n",
       "      <td>3200000.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>music singer songwriting</td>\n",
       "      <td>948300.0</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  NAME                  USERNAME  FOLLOWERS  \\\n",
       "0  Pashto Entertainment Entertainment   UC5o5At6pto0EYYa0-m3GIiA    19400.0   \n",
       "1                         Rashid Khan              rashid.khan19  9100000.0   \n",
       "2                       Steve McCurry       stevemccurryofficial  3600000.0   \n",
       "3                        د. وسيم يوسف              waseem_yousef  3300000.0   \n",
       "4           AHMAD SAEEDI / احمد سعيدي               ahmadsaeedi1  3200000.0   \n",
       "\n",
       "     ER      COUNTRY        TOPIC OF INFLUENCE  POTENTIAL REACH    CHANNEL  \n",
       "0  1.10  Afghanistan                 celebrity           5800.0    youtube  \n",
       "1  6.19  Afghanistan            cricket sports        2700000.0  instagram  \n",
       "2  1.07  Afghanistan                       art        1100000.0  instagram  \n",
       "3  0.19  Afghanistan               celebrities         993100.0  instagram  \n",
       "4  1.71  Afghanistan  music singer songwriting         948300.0  instagram  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "merged_df = pd.read_csv('merged_influencer_data.csv')\n",
    "\n",
    "# Split the 'NAME' column at '@', but only if '@' is present\n",
    "merged_df[['NAME', 'USERNAME']] = merged_df['NAME'].str.split('@', n=1, expand=True)\n",
    "\n",
    "# Handle cases where '@' is not found (USERNAME will be None)\n",
    "merged_df['USERNAME'] = merged_df['USERNAME'].fillna('')\n",
    "\n",
    "# Remove leading whitespace from 'USERNAME' (if any)\n",
    "merged_df['USERNAME'] = merged_df['USERNAME'].str.lstrip()\n",
    "\n",
    "# Get a list of columns\n",
    "cols = list(merged_df.columns)\n",
    "\n",
    "# Move 'USERNAME' to the index after 'NAME'\n",
    "cols.insert(cols.index('NAME') + 1, cols.pop(cols.index('USERNAME')))\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "merged_df = merged_df[cols]\n",
    "\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41cdf18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find rows where 'USERNAME' is 'some_username'\n",
    "# matching_rows = merged_df.query('USERNAME == \"britneyspears\"')\n",
    "# print(matching_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80da7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame\n",
    "merged_df.to_csv('merged_influencer_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80643eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9122 entries, 0 to 9121\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   NAME                9122 non-null   object \n",
      " 1   USERNAME            9122 non-null   object \n",
      " 2   FOLLOWERS           9122 non-null   float64\n",
      " 3   ER                  9122 non-null   float64\n",
      " 4   COUNTRY             9047 non-null   object \n",
      " 5   TOPIC OF INFLUENCE  9122 non-null   object \n",
      " 6   POTENTIAL REACH     9122 non-null   float64\n",
      " 7   CHANNEL             9122 non-null   object \n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 570.3+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92c58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /opt/anaconda3/lib/python3.11/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (2.0.7)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2dd082e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /opt/anaconda3/lib/python3.11/site-packages (0.1.22)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from opendatasets) (4.65.0)\n",
      "Requirement already satisfied: kaggle in /opt/anaconda3/lib/python3.11/site-packages (from opendatasets) (1.6.17)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.11/site-packages (from opendatasets) (8.1.7)\n",
      "Requirement already satisfied: six>=1.10 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2.31.0)\n",
      "Requirement already satisfied: python-slugify in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (2.0.7)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.11/site-packages (from kaggle->opendatasets) (4.1.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from bleach->kaggle->opendatasets) (23.1)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.11/site-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kaggle->opendatasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->kaggle->opendatasets) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80372ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.11/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e94f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/syedjaferk/top-1000-instagrammers-world-cleaned\n",
      "Downloading top-1000-instagrammers-world-cleaned.zip to ./top-1000-instagrammers-world-cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 21.5k/21.5k [00:00<00:00, 3.02MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od \n",
    "\n",
    "\n",
    "od.download( \"https://www.kaggle.com/datasets/syedjaferk/top-1000-instagrammers-world-cleaned/data\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3c1aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/faisaljanjua0555/top-200-most-followed-instagram-accounts-2023\n",
      "Downloading top-200-most-followed-instagram-accounts-2023.zip to ./top-200-most-followed-instagram-accounts-2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4.67k/4.67k [00:00<00:00, 1.99MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/datasets/faisaljanjua0555/top-200-most-followed-instagram-accounts-2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aa3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nbconvert in /opt/anaconda3/lib/python3.11/site-packages (7.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (3.1.3)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (5.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (0.1.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (5.9.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (23.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (1.5.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (2.15.1)\n",
      "Requirement already satisfied: tinycss2 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (1.2.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from nbconvert) (5.7.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert) (0.5.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-core>=4.7->nbconvert) (3.10.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/anaconda3/lib/python3.11/site-packages (from nbclient>=0.5.0->nbconvert) (7.4.9)\n",
      "Requirement already satisfied: fastjsonschema in /opt/anaconda3/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert) (4.19.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->nbconvert) (2.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.10.6)\n",
      "Requirement already satisfied: entrypoints in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (0.4)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/lib/python3.11/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbconvert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fddffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandoc\n",
      "  Downloading pandoc-2.4.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plumbum (from pandoc)\n",
      "  Downloading plumbum-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: ply in /opt/anaconda3/lib/python3.11/site-packages (from pandoc) (3.11)\n",
      "Downloading plumbum-1.9.0-py3-none-any.whl (127 kB)\n",
      "Building wheels for collected packages: pandoc\n",
      "  Building wheel for pandoc (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandoc: filename=pandoc-2.4-py3-none-any.whl size=34794 sha256=ca1fbee1fa6a3606457c89d2efde8733d4f47f274f9470fcd2069ea39a6de661\n",
      "  Stored in directory: /Users/flavialooker/Library/Caches/pip/wheels/4f/d7/32/c6c9b7b05e852e920fd72174487be3a0f18e633a7adcc303be\n",
      "Successfully built pandoc\n",
      "Installing collected packages: plumbum, pandoc\n",
      "Successfully installed pandoc-2.4 plumbum-1.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61af59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
